{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68489182",
   "metadata": {},
   "source": [
    "Workflow de Extração e Análise de Acurácia de OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652b0ab",
   "metadata": {},
   "source": [
    "### 1. Instalação\n",
    "Execute esta célula uma vez para instalar todas as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f345a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install paddleocr paddlepaddle python-Levenshtein -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4e14a",
   "metadata": {},
   "source": [
    "ou esta para instalar os requirements, caso tudo já esteja lá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059504f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11871463",
   "metadata": {},
   "source": [
    "### 2. Importação e Inicialização\n",
    "Importação das bibliotecas e preparamos o modelo de OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import json\n",
    "import re\n",
    "import Levenshtein\n",
    "import os\n",
    "import unicodedata\n",
    "import requests\n",
    "from settings.settings import importar_configs\n",
    "\n",
    "st = importar_configs()\n",
    "\n",
    "ocr = PaddleOCR(lang='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707699a0",
   "metadata": {},
   "source": [
    "### 3. Caminho da Imagem e Obtenção do Texto\n",
    "Defina o caminho para a sua imagem nesta célula e execute para realizar a extração do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_img = 'tmp/imagem_digitalizada.jpeg'\n",
    "\n",
    "resultados = None \n",
    "\n",
    "if not os.path.exists(caminho_img):\n",
    "    print(f\"A imagem não foi encontrada em '{caminho_img}'\")\n",
    "else:\n",
    "    print(f\"Lendo a imagem: {caminho_img}...\")\n",
    "    resultados = ocr.predict(caminho_img)\n",
    "    print(\"Texto extraído com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253670d5",
   "metadata": {},
   "source": [
    "### 4. Mostrando Resultados da Extração\n",
    "Esta célula mostra o texto \"cru\" que foi extraído pelo OCR na etapa anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if resultados and resultados[0]:\n",
    "    print(\"--- Texto Extraído ---\")\n",
    "    \n",
    "    lista_de_textos = resultados[0]['rec_texts']\n",
    "    \n",
    "    for texto in lista_de_textos:\n",
    "        print(texto)\n",
    "        \n",
    "    print(\"----------------------\")\n",
    "else:\n",
    "    print(\"Nenhum texto foi detectado ou a célula anterior não foi executada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_acentos(texto):\n",
    "    \"\"\"Remove acentuação de um texto para facilitar busca.\"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', texto)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def extrair_valor(padrao, texto, grupo=1, default=\"NÃO ACHOU NADAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"):\n",
    "    \"\"\"\n",
    "    Função auxiliar para extrair valor com regex de forma segura,\n",
    "    ignorando acentos ao buscar, e retornando texto original com possivel acento.\n",
    "    \"\"\"\n",
    "    texto_sem_acentos = remover_acentos(texto).lower()\n",
    "    padrao_sem_acentos = remover_acentos(padrao).lower()\n",
    "\n",
    "    # Faz busca no texto sem acento\n",
    "    match = re.search(padrao_sem_acentos, texto_sem_acentos)\n",
    "\n",
    "    if not match:\n",
    "        return default\n",
    "\n",
    "    if grupo == 0:  # pegar texto completo correspondido\n",
    "        inicio, fim = match.start(), match.end()\n",
    "        return texto[inicio:fim].strip()\n",
    "\n",
    "    if len(match.groups()) >= grupo:\n",
    "        # Capture o trecho sem acentos do grupo e tentamos localizar ele no texto original para preservar acentos\n",
    "        valor_sem_acentos = match.group(grupo)\n",
    "        pos = texto_sem_acentos.find(valor_sem_acentos)\n",
    "        if pos != -1:\n",
    "            # Retorna trecho do texto original que corresponde a parte achada\n",
    "            return texto[pos:pos+len(valor_sem_acentos)].strip()\n",
    "        else:\n",
    "            # Caso não ache, devolve valor sem acentos mesmo\n",
    "            return valor_sem_acentos.strip()\n",
    "\n",
    "    return default\n",
    "\n",
    "def extrair_revistas_de_texto(texto_completo):\n",
    "    linhas = texto_completo.splitlines()\n",
    "\n",
    "    # Encontrar o índice onde começa a seção de revistas\n",
    "    try:\n",
    "        idx_inicio = next(i for i, linha in enumerate(linhas) if \"REVISTAS\" in linha)\n",
    "        idx_fim = next(i for i, s in enumerate(linhas) if s.lower().startswith(\"quant itens\"))\n",
    "        idx_cabecalho_fim = next((i for i, s in enumerate(linhas[idx_inicio:idx_fim]) if 'VIr.Venda' in s), 0)\n",
    "        linhas_revistas = linhas[idx_inicio + idx_cabecalho_fim + 1 : idx_fim]\n",
    "    except StopIteration:\n",
    "        return []  # Não achou seção revistas\n",
    "\n",
    "    return '\\n'.join(linhas_revistas)\n",
    "\n",
    "def obter_json_revistas(prompt):\n",
    "    \"\"\"\n",
    "    Envia o prompt para a API de IA e retorna o JSON extraído da resposta.\n",
    "    \"\"\"\n",
    "    url = \"https://openrouter.ai/api/v1/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistralai/mistral-7b-instruct:free\",\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer {}\".format(st.OPENROUTER_API),\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    texto = response.json()['choices'][0]['text']\n",
    "    return texto\n",
    "\n",
    "def remover_json_da_resposta(texto_ia):\n",
    "    # Procura o conteúdo entre ``````\n",
    "    padrao = r\"```json(.*?)```\"\n",
    "    match = re.search(padrao, texto_ia, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        # Se não encontrar com json, tenta pegar entre ``````\n",
    "        padrao_simples = r\"``````\"\n",
    "        match_simples = re.search(padrao_simples, texto_ia, re.DOTALL)\n",
    "        if match_simples:\n",
    "            return match_simples.group(1)\n",
    "    # Caso não ache nada, retorna o texto original\n",
    "    return texto_ia.strip()\n",
    "\n",
    "def transformar_texto_em_json(texto_extraido):\n",
    "    \"\"\"\n",
    "    Analisa o texto bruto do OCR e o transforma em um dicionário estruturado (JSON).\n",
    "    \"\"\"\n",
    "\n",
    "    texto_completo = texto_extraido\n",
    "    \n",
    "    json_final = {\n",
    "        \"empresa\": {\n",
    "        \"nome\": \"APACHE LOGÍSTICA\",\n",
    "        \"endereco\": \"Rua Prefeito Olímpio de Melo n° 1828\",\n",
    "        \"bairro\":\"Benfica\",\n",
    "        \"cidade\": \"Rio de Janeiro\",\n",
    "        \"estado\": \"RJ\",\n",
    "        \"cep\": \"20930-005\",\n",
    "        \"telefones\": \"\"\n",
    "        },\n",
    "        \"chamada_encalhe\": {\n",
    "            \"ce\": \"\", \n",
    "            \"data_da_chamada\": \"\", \n",
    "            \"dia_semana\": \"\", \n",
    "            \"ponto\": \"\",\n",
    "            \"cliente\": {\n",
    "                \"nome\": \"\", \n",
    "                \"endereco\": \"\", \n",
    "                \"telefone\": \"\", \n",
    "                \"cep\": \"\", \n",
    "                \"bairro\": \"Barra da Tijuca\", \n",
    "                \"cidade\": \"Rio de Janeiro\"\n",
    "            },\n",
    "            \"local_entrega\": \"\", \n",
    "            \"horario\": \"\", \n",
    "            \"responsavel\": \"\", \n",
    "            \"numero_chamada\": \"\"\n",
    "        },\n",
    "        \"solucao\": \"\", \n",
    "        \"revistas\": [],\n",
    "        \"totais\": {\"quantidade_itens\": \"\", \"total_entregue\": \"\", \"volume\": \"\", \"total_entregue_geral\": \"\", \"volume_geral\": \"\"},\n",
    "        \"observacoes\": \"\", \n",
    "        \"data_documento\": \"\"\n",
    "    }\n",
    "\n",
    "    json_final[\"data_documento\"] = extrair_valor(r'(\\d{2}/\\d{2}/\\d{4}) \\d{2}.\\d{2}.\\d{2}P.*:', texto_completo)\n",
    "\n",
    "    try:\n",
    "        limite_cabecalho = texto_completo.index('CHAMADA DE ENCALHE')\n",
    "        texto_cabecalho = texto_completo[:limite_cabecalho]\n",
    "    except ValueError:\n",
    "        texto_cabecalho = texto_completo\n",
    "    json_final[\"empresa\"][\"telefones\"] = re.findall(r\"(\\(\\d{2}\\)\\s*\\d{4,5}[-.\\s]*\\d{4})\", texto_cabecalho)\n",
    "    \n",
    "    json_final[\"chamada_encalhe\"][\"ce\"] = extrair_valor(r\"CE\\s*:\\s*(\\d+)\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"data_da_chamada\"] = extrair_valor(r\"Data da chamada\\s*(\\d{2}/\\d{2}/\\d{4})\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"dia_semana\"] = extrair_valor(r\"(Terça feira)\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"ponto\"] = extrair_valor(r\"Pont.*?\\s*(\\d+)\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"numero_chamada\"] = json_final[\"chamada_encalhe\"][\"ponto\"]\n",
    "    \n",
    "    json_final[\"chamada_encalhe\"][\"cliente\"][\"nome\"] = extrair_valor(r\"Pont.*?\\d+\\s+(.*?)\\s+CEP\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"cliente\"][\"endereco\"] = extrair_valor(r\"(Avenida Armando Lombardi, \\d+)\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"cliente\"][\"telefone\"] = extrair_valor(r\"Tel:\\s*([()\\d-]+)\", texto_completo)\n",
    "    json_final[\"chamada_encalhe\"][\"cliente\"][\"cep\"] = extrair_valor(r\"CEP\\s*(\\d{5}-\\d{3})\", texto_completo)\n",
    "    \n",
    "    json_final[\"chamada_encalhe\"][\"responsavel\"] = extrair_valor(r\"Resp\\.:\\s*(.*)\", texto_completo)\n",
    "    json_final[\"solucao\"] = extrair_valor(r\"(\\d+\\s+SOLUÇÃO\\s+\\d+)\", texto_completo)\n",
    "\n",
    "    json_final[\"totais\"][\"quantidade_itens\"] = extrair_valor(r\"Quant itens\\s+(\\d+)\", texto_completo)\n",
    "    json_final[\"totais\"][\"total_entregue\"] = extrair_valor(r\"Total entre(?:g|q)ue:\\s*([\\d.,]+)\", texto_completo)\n",
    "    json_final[\"totais\"][\"volume\"] = extrair_valor(r\"Vols.*\\s*.*\\s*:\\s*(\\d+)\", texto_completo)\n",
    "    json_final[\"totais\"][\"total_entregue_geral\"] = extrair_valor(r\"Total entregue geral:\\s*([\\d.,]+)\", texto_completo)\n",
    "    json_final[\"totais\"][\"volume_geral\"] = extrair_valor(r\"Vols\\.\\(geral\\):\\s*(\\d+)\", texto_completo)\n",
    "    \n",
    "    obs_match = extrair_valor(r\"Observações\\s*(PREZADO JORNALEIRO[\\s\\S]*)\", texto_completo)\n",
    "    if obs_match:\n",
    "        observacao_limpa = obs_match.split('---')[0]\n",
    "        json_final[\"observacoes\"] = \" \".join(observacao_limpa.split()).strip()\n",
    "\n",
    "\n",
    "    revistas_texto_bruto = extrair_revistas_de_texto(texto_completo)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Você receberá um texto bruto com dados de revistas extraídos de OCR, onde os dados podem estar incompletos, fora de ordem ou misturados. Sua tarefa é reconhecer cada informação, identificar a qual campo da revista ela pertence, e estruturar todas as revistas em um JSON com o formato abaixo:\n",
    "\n",
    "    {{\n",
    "    \"revistas\": [\n",
    "        {{\n",
    "        \"produto\": \"Nome do Produto\",\n",
    "        \"subtitulo\": \"Subtítulo ou autor\",\n",
    "        \"ean\": \"Código EAN\",\n",
    "        \"edicao\": \"Número da edição\",\n",
    "        \"entrega\": \"Data de entrega no formato dd/mm/aaaa\",\n",
    "        \"pco_capa\": \"Preço de capa, com vírgula decimal\",\n",
    "        \"rep\": \"Quantidade de repostas\",\n",
    "        \"encalhe\": \"Quantidade de encalhe\",\n",
    "        \"venda\": \"Quantidade de venda (pode ser vazio)\",\n",
    "        \"pco_liq\": \"Preço líquido, com vírgula decimal\",\n",
    "        \"vir_venda\": \"Quantidade virada para venda (pode ser vazio)\"\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "\n",
    "    Lembre-se:\n",
    "    - Os dados podem vir desorganizados, incompletos ou em ordem diferente.\n",
    "    - Você deve agrupar as informações corretas para cada revista.\n",
    "    - Se algum campo estiver faltando, preencha com string vazia \"\".\n",
    "    - Mantenha o formato de data dd/mm/aaaa e preços com vírgula decimal.\n",
    "    - Não adicione explicações, retorne apenas o JSON válido.\n",
    "\n",
    "    Aqui estão exemplos de como o JSON final deve ficar para algumas revistas:\n",
    "\n",
    "    {{\n",
    "    \"revistas\": [\n",
    "        {{\n",
    "        \"produto\": \"A LANCA LENDÁRIA E O ESCUDO IMPENETRÁVEL\",\n",
    "        \"subtitulo\": \"TOTOFUMI\",\n",
    "        \"ean\": \"9786525915104 01\",\n",
    "        \"edicao\": \"00001\",\n",
    "        \"entrega\": \"04/06/2025\",\n",
    "        \"pco_capa\": \"39,90\",\n",
    "        \"rep\": \"2\",\n",
    "        \"encalhe\": \"1\",\n",
    "        \"venda\": \"\",\n",
    "        \"pco_liq\": \"27,930\",\n",
    "        \"vir_venda\": \"\"\n",
    "        }},\n",
    "        {{\n",
    "        \"produto\": \"A MISTERIOSA LOJA DE PENHORES\",\n",
    "        \"subtitulo\": \"GO SUYOO\",\n",
    "        \"ean\": \"97865935775\",\n",
    "        \"edicao\": \"00001\",\n",
    "        \"entrega\": \"25/06/2025\",\n",
    "        \"pco_capa\": \"49,90\",\n",
    "        \"rep\": \"2\",\n",
    "        \"encalhe\": \"1\",\n",
    "        \"venda\": \"1\",\n",
    "        \"pco_liq\": \"34,930\",\n",
    "        \"vir_venda\": \"\"\n",
    "        }},\n",
    "        {{\n",
    "        \"produto\": \"A RECREATIVA\",\n",
    "        \"subtitulo\": \"JOÃO FONSCA, TENISTA Nº 1 DO BRASIL\",\n",
    "        \"ean\": \"977141397900900496\",\n",
    "        \"edicao\": \"00496\",\n",
    "        \"entrega\": \"23/07/2025\",\n",
    "        \"pco_capa\": \"38,90\",\n",
    "        \"rep\": \"2\",\n",
    "        \"encalhe\": \"\",\n",
    "        \"venda\": \"\",\n",
    "        \"pco_liq\": \"27,230\",\n",
    "        \"vir_venda\": \"\"\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "\n",
    "    Agora, organize o texto abaixo seguindo essas regras e o formato JSON esperado, e retorne apenas o JSON válido, sem explicações ou comentários:\n",
    "\n",
    "    \\\"\\\"\\\"\n",
    "    {revistas_texto_bruto}\n",
    "    \\\"\\\"\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    revistas = remover_json_da_resposta(obter_json_revistas(prompt))\n",
    "    json_final[\"revistas\"] = json.loads(revistas).get(\"revistas\", [])\n",
    "\n",
    "    return json_final\n",
    "\n",
    "if 'lista_de_textos' in locals() and lista_de_textos:\n",
    "    texto_completo_extraido = \"\\n\".join(lista_de_textos)\n",
    "    \n",
    "    json_estruturado = transformar_texto_em_json(texto_completo_extraido)\n",
    "\n",
    "    # salva em um arquivo JSON\n",
    "    with open(\"chamada.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_estruturado, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    print(\"JSON salvo em 'saida.json'\")\n",
    "else:\n",
    "    print(\"Execute a célula de OCR primeiro para gerar a 'lista_de_textos'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b040c",
   "metadata": {},
   "source": [
    "# Função para a IA do OpenRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = f\"\"\"\n",
    "Você receberá um texto bruto com dados de revistas extraídos de OCR, onde os dados podem estar incompletos, fora de ordem ou misturados. Sua tarefa é reconhecer cada informação, identificar a qual campo da revista ela pertence, e estruturar todas as revistas em um JSON com o formato abaixo:\n",
    "\n",
    "{{\n",
    "  \"revistas\": [\n",
    "    {{\n",
    "      \"produto\": \"Nome do Produto\",\n",
    "      \"subtitulo\": \"Subtítulo ou autor\",\n",
    "      \"ean\": \"Código EAN\",\n",
    "      \"edicao\": \"Número da edição\",\n",
    "      \"entrega\": \"Data de entrega no formato dd/mm/aaaa\",\n",
    "      \"pco_capa\": \"Preço de capa, com vírgula decimal\",\n",
    "      \"rep\": \"Quantidade de repostas\",\n",
    "      \"encalhe\": \"Quantidade de encalhe\",\n",
    "      \"venda\": \"Quantidade de venda (pode ser vazio)\",\n",
    "      \"pco_liq\": \"Preço líquido, com vírgula decimal\",\n",
    "      \"vir_venda\": \"Quantidade virada para venda (pode ser vazio)\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Lembre-se:\n",
    "- Os dados podem vir desorganizados, incompletos ou em ordem diferente.\n",
    "- Você deve agrupar as informações corretas para cada revista.\n",
    "- Se algum campo estiver faltando, preencha com string vazia \"\".\n",
    "- Mantenha o formato de data dd/mm/aaaa e preços com vírgula decimal.\n",
    "- Não adicione explicações, retorne apenas o JSON válido.\n",
    "\n",
    "Aqui estão exemplos de como o JSON final deve ficar para algumas revistas:\n",
    "\n",
    "{{\n",
    "  \"revistas\": [\n",
    "    {{\n",
    "      \"produto\": \"A LANCA LENDÁRIA E O ESCUDO IMPENETRÁVEL\",\n",
    "      \"subtitulo\": \"TOTOFUMI\",\n",
    "      \"ean\": \"9786525915104 01\",\n",
    "      \"edicao\": \"00001\",\n",
    "      \"entrega\": \"04/06/2025\",\n",
    "      \"pco_capa\": \"39,90\",\n",
    "      \"rep\": \"2\",\n",
    "      \"encalhe\": \"1\",\n",
    "      \"venda\": \"\",\n",
    "      \"pco_liq\": \"27,930\",\n",
    "      \"vir_venda\": \"\"\n",
    "    }},\n",
    "    {{\n",
    "      \"produto\": \"A MISTERIOSA LOJA DE PENHORES\",\n",
    "      \"subtitulo\": \"GO SUYOO\",\n",
    "      \"ean\": \"97865935775\",\n",
    "      \"edicao\": \"00001\",\n",
    "      \"entrega\": \"25/06/2025\",\n",
    "      \"pco_capa\": \"49,90\",\n",
    "      \"rep\": \"2\",\n",
    "      \"encalhe\": \"1\",\n",
    "      \"venda\": \"1\",\n",
    "      \"pco_liq\": \"34,930\",\n",
    "      \"vir_venda\": \"\"\n",
    "    }},\n",
    "    {{\n",
    "      \"produto\": \"A RECREATIVA\",\n",
    "      \"subtitulo\": \"JOÃO FONSCA, TENISTA Nº 1 DO BRASIL\",\n",
    "      \"ean\": \"977141397900900496\",\n",
    "      \"edicao\": \"00496\",\n",
    "      \"entrega\": \"23/07/2025\",\n",
    "      \"pco_capa\": \"38,90\",\n",
    "      \"rep\": \"2\",\n",
    "      \"encalhe\": \"\",\n",
    "      \"venda\": \"\",\n",
    "      \"pco_liq\": \"27,230\",\n",
    "      \"vir_venda\": \"\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Agora, organize o texto abaixo seguindo essas regras e o formato JSON esperado, e retorne apenas o JSON válido, sem explicações ou comentários:\n",
    "\n",
    "\\\"\\\"\\\"\n",
    "{texto_completo_extraido}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "def obter_json_revistas(prompt):\n",
    "    \"\"\"\n",
    "    Envia o prompt para a API de IA e retorna o JSON extraído da resposta.\n",
    "    \"\"\"\n",
    "    url = \"https://openrouter.ai/api/v1/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistralai/mistral-7b-instruct:free\",\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + os.getenv(\"OPENROUTER_API\"),\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    texto = response.json()['choices'][0]['text']\n",
    "    return texto\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
